---
title: "Proyecto 2. Entrega 6. SVM"
author: 
  - "Pablo Daniel Barillas Moreno, Carn√© No. 22193"
  - "Mathew Cordero Aquino, Carn√© No. 22982"
output:
  pdf_document:
    latex_engine: xelatex
  html_document: default
always_allow_html: true
date: "2025-03-14"
header-includes:
   - \usepackage{fvextra}
   - \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
repository: "https://github.com/DanielBarillas/Proyecto-2_Entrega-6_SVM.git"
---

### Enlace al Repositorio del proyecto 2 - Entrega 5 de miner√≠a de datos del Grupo #1
[Repositorio en GitHub](https://github.com/DanielBarillas/Proyecto-2_Entrega-6_SVM.git)

### 0. Descargue los conjuntos de datos. 

Para este punto, ya se ha realizado el proceso para descargar del sitio web: [House Prices - Advanced Regression Techniques](https://kaggle.com/competitions/house-prices-advanced-regression-techniques), la data de entrenamiento y la data de prueba, ambos extra√≠dos desde la carpeta "house_prices_data/" en data frames llamados train_data (data de entrenamiento) y test_data (data de prueba), sin convertir autom√°ticamente las variables categ√≥ricas en factores (stringsAsFactors = FALSE). Luego, se realiza una inspecci√≥n inicial de train_data mediante tres funciones: head(train_data), que muestra las primeras filas del dataset; str(train_data), que despliega la estructura del data frame, incluyendo el tipo de cada variable; y summary(train_data), que proporciona un resumen estad√≠stico de las variables num√©ricas y una descripci√≥n general de las categ√≥ricas.

```{r}
  train_data <- read.csv("train_set.csv", stringsAsFactors = FALSE)
  test_data <- read.csv("test_set.csv", stringsAsFactors = FALSE)
  
  head(train_data)   # Muestra las primeras filas
  str(train_data)    # Muestra la estructura del dataset
  summary(train_data) # Resumen estad√≠stico
```

### 1. Use los mismos conjuntos de entrenamiento y prueba de las hojas de trabajo pasadas para probar el algoritmo. 

```{r}
# üì¶ Cargar librer√≠as necesarias
library(dplyr)
library(readr)

# üîÑ Fijar semilla para reproducibilidad
set.seed(123)

# üìÇ Cargar los conjuntos de datos previamente usados
train <- read_csv("train_set.csv")
test <- read_csv("test_set.csv")

# üëÅÔ∏è Verificar estructura general y dimensiones
cat("Observaciones en train:", nrow(train), "\n")
cat("Observaciones en test:", nrow(test), "\n")

# ‚úÖ Asegurar que la variable de salida es factor
train$SalePriceCat <- as.factor(train$SalePriceCat)
test$SalePriceCat <- as.factor(test$SalePriceCat)

# üîç Verificar primeras observaciones de inter√©s
cat("\nPrimeras observaciones:\n")
print(head(train[, c("SalePrice", "SalePriceCat")]))

# üìä Frecuencia de clases en el conjunto de entrenamiento
cat("\nDistribuci√≥n de SalePriceCat en train:\n")
print(table(train$SalePriceCat))

# üîé Confirmar estructura de la variable objetivo
cat("\nEstructura de la variable SalePriceCat:\n")
str(train$SalePriceCat)
```

**üìÑ Exploraci√≥n inicial de los datos**

Al cargar los conjuntos de datos `train_set.csv` y `test_set.csv`, se obtuvo una salida descriptiva autom√°tica proporcionada por la funci√≥n `read_csv()` del paquete `readr`. Esta salida indica que ambos conjuntos tienen exactamente **84 columnas**, divididas en:

- **42 columnas de tipo car√°cter (`chr`)**, correspondientes a variables **categ√≥ricas**, como `MSZoning`, `Neighborhood`, `BldgType`, entre otras.
- **42 columnas de tipo num√©rico (`dbl`)**, como `LotArea`, `OverallQual`, `GrLivArea`, `SalePrice`, etc.

Tambi√©n se observa que:

- El conjunto de entrenamiento contiene **937 observaciones**.
- El conjunto de prueba contiene **232 observaciones**.

Adem√°s, se valid√≥ que la variable categ√≥rica objetivo `SalePriceCat` (con niveles: `barata`, `media`, `cara`) est√© correctamente codificada como factor. La distribuci√≥n de clases en el conjunto de entrenamiento es **perfectamente balanceada**, con **313 observaciones para "barata"**, **312 para "media"**, y **312 para "cara"**.

Finalmente, se visualizaron las primeras observaciones para comprobar que los valores de `SalePrice` y su categor√≠a `SalePriceCat` coinciden correctamente:

| SalePrice | SalePriceCat |
|-----------|--------------|
| 223500    | cara         |
| 250000    | cara         |
| 307000    | cara         |
| 200000    | cara         |
| 118000    | barata       |
| 144000    | media        |

Esto confirma que los datos est√°n correctamente cargados y estructurados para entrenar un modelo de clasificaci√≥n con SVM en las siguientes etapas.

### 2. Explore los datos y explique las transformaciones que debe hacerle para generar un modelo de m√°quinas vectoriales de soporte. 

Para entrenar un modelo de m√°quinas de vectores de soporte (**SVM**), es fundamental preparar los datos adecuadamente. A continuaci√≥n se describen las transformaciones necesarias y el porqu√© de cada una:


**üîπ 1. Codificaci√≥n de variables categ√≥ricas**

Las m√°quinas SVM no pueden trabajar directamente con variables de tipo `character` o `factor`. Por lo tanto, es necesario transformar todas las variables **categ√≥ricas** en variables **dummy** o **indicadoras**. Esto se puede lograr f√°cilmente usando `model.matrix()` o funciones autom√°ticas de preprocesamiento de `caret`.


**üîπ 2. Normalizaci√≥n de variables num√©ricas**

SVM es muy sensible a la escala de los datos. Por eso, es **obligatorio escalar (normalizar)** las variables num√©ricas, especialmente cuando se usa un **kernel radial o polin√≥mico**. Esto se har√° con `preProcess = c("center", "scale")`.


**üîπ 3. Selecci√≥n de variables relevantes**

Dado que tenemos 84 variables, muchas de ellas pueden no aportar al modelo o incluso introducir ruido. Para este experimento inicial, se usar√°n **solo variables num√©ricas puras**, excluyendo el `Id` y la variable objetivo.

```{r}
# üì¶ Librer√≠as necesarias
library(caret)
library(dplyr)

# üîÑ Semilla
set.seed(123)

# üßπ Eliminar columna Id
train_svm <- train %>% select(-Id)
test_svm  <- test %>% select(-Id)

# üéØ Variables objetivo
y_train <- train_svm$SalePriceCat
y_test  <- test_svm$SalePriceCat

# üîç Separar predictores
x_train <- train_svm %>% select(-SalePrice, -SalePriceCat)
x_test  <- test_svm %>% select(-SalePrice, -SalePriceCat)

# üîÅ Convertir character a factor
x_train <- x_train %>% mutate(across(where(is.character), as.factor))
x_test  <- x_test %>% mutate(across(where(is.character), as.factor))

# üß© Combinar para detectar todos los niveles posibles
x_all <- bind_rows(x_train, x_test)

# ‚öôÔ∏è Crear dummyVars con todos los niveles presentes
dv <- dummyVars(" ~ .", data = x_all, fullRank = TRUE)

# üîÑ Generar dummies por separado
x_train_dummy <- predict(dv, newdata = x_train)
x_test_dummy  <- predict(dv, newdata = x_test)

# üßº Preprocesar (centrar y escalar)
preproc <- preProcess(x_train_dummy, method = c("center", "scale"))
x_train_scaled <- predict(preproc, x_train_dummy)
x_test_scaled  <- predict(preproc, x_test_dummy)

# ‚úÖ Confirmaci√≥n
cat("‚úîÔ∏è Datos listos para entrenar SVM sin errores de niveles\n")
cat("Train:", dim(x_train_scaled), " | Test:", dim(x_test_scaled), "\n")
```
**üìå Conclusi√≥n**

> Las transformaciones realizadas ‚Äî**dummificaci√≥n de variables categ√≥ricas**, **normalizaci√≥n de variables num√©ricas**, y **selecci√≥n de variables relevantes**‚Äî son esenciales para garantizar el correcto funcionamiento de los modelos SVM, especialmente cuando se usan kernels no lineales. Esto deja los datos completamente preparados para entrenar modelos en el siguiente paso.

### üßº Preprocesamiento exitoso de los datos para SVM

Al finalizar el preprocesamiento, el sistema report√≥ lo siguiente:

```
Aviso: These variables have zero variances: Neighborhood.Blueste, Condition2.RRAn, RoofStyle.Shed, Foundation.Wood, Electrical.Mix, GarageQual.Po
‚úîÔ∏è Datos listos para entrenar SVM sin errores de niveles
Train: 937 243  | Test: 232 243
```

Este mensaje entrega **dos piezas clave de informaci√≥n**:

**1. Variables con varianza cero**

> *These variables have zero variances: ...*

Esto significa que esas variables dummy (creadas a partir de variables categ√≥ricas) **tienen el mismo valor en todas las observaciones del conjunto de entrenamiento**, usualmente 0. Esto ocurre cuando:

- Ninguna observaci√≥n del `train` pertenece a esa categor√≠a.
- La categor√≠a existe en el conjunto de prueba, pero **no fue representada en `train`**.

Ejemplo: si ninguna vivienda en `train` est√° en el vecindario *Blueste*, entonces la variable `Neighborhood.Blueste` ser√° 0 en todas las filas.

Estas variables:
- ‚ùå **No aportan informaci√≥n √∫til** al modelo.
- ‚úÖ **No generan errores**.
- üßπ Se pueden eliminar si se desea un modelo m√°s limpio.

**2. Confirmaci√≥n del preprocesamiento**

> *‚úîÔ∏è Datos listos para entrenar SVM sin errores de niveles*

Esta l√≠nea confirma que los datos han sido correctamente:
- Dummyficados (variables categ√≥ricas convertidas en columnas binarias),
- Escalados (centrados y normalizados),
- Sin problemas de categor√≠as nuevas en `test` (gracias a `dummyVars()` entrenado sobre `train + test` juntos),
- Listos para pasar al modelo SVM.

Tambi√©n se reportaron las **dimensiones finales** de los datos:

- `Train: 937 observaciones y 243 variables`
- `Test: 232 observaciones y 243 variables`  
  ‚Üí Lo que asegura que ambos conjuntos tienen la **misma estructura** y est√°n completamente sincronizados para su uso en modelos.

**‚úÖ Conclusi√≥n**

Los datos han sido preprocesados correctamente para entrenar modelos SVM multiclase. Las variables con varianza cero no representan errores, pero se pueden eliminar opcionalmente. El pipeline garantiza que el conjunto de entrenamiento y prueba est√°n listos para ser utilizados en modelos sin errores de contraste ni estructura.

### 3. Use como variable respuesta la variable categ√≥rica que especifica si la casa es barata, media o cara 

```{r}
# üì¶ Librer√≠as necesarias
library(caret)
library(dplyr)

# üîÑ Fijar semilla
set.seed(123)

# üßº Convertir los dummy a data.frame
x_train_dummy <- as.data.frame(x_train_dummy)
x_test_dummy  <- as.data.frame(x_test_dummy)

# üí£ Eliminar columnas con varianza 0 en train
varianzas <- apply(x_train_dummy, 2, var)
cols_validas <- names(varianzas[!is.na(varianzas) & varianzas > 0])
x_train_dummy <- x_train_dummy[, cols_validas]

# üß© Alinear columnas en test (agregar faltantes con 0)
faltantes <- setdiff(cols_validas, colnames(x_test_dummy))
for (col in faltantes) {
  x_test_dummy[[col]] <- 0
}

# üîÑ Reordenar columnas en test para que coincidan con train
x_test_dummy <- x_test_dummy[, cols_validas]

# ‚úÖ Confirmaci√≥n de que est√°n alineadas
stopifnot(identical(colnames(x_train_dummy), colnames(x_test_dummy)))

# ‚öñÔ∏è Escalar datos
preproc <- preProcess(x_train_dummy, method = c("center", "scale"))
x_train_scaled <- predict(preproc, x_train_dummy)
x_test_scaled  <- predict(preproc, x_test_dummy)

# ü§ñ Entrenar modelo SVM lineal con fallback a SVM radial
cat("üéØ Entrenando modelo SVM lineal...\n")
tryCatch({
  svm_linear_model <- train(
    x = x_train_scaled,
    y = y_train,
    method = "svmLinear",
    trControl = trainControl(method = "cv", number = 10),
    preProcess = NULL,
    tuneLength = 3
  )
  print(svm_linear_model)
}, error = function(e) {
  cat("‚ùå SVM lineal fall√≥. Cambiando a SVM radial...\n")
  svm_linear_model <<- train(
    x = x_train_scaled,
    y = y_train,
    method = "svmRadial",
    trControl = trainControl(method = "cv", number = 10),
    preProcess = NULL,
    tuneLength = 3
  )
  print(svm_linear_model)
})
```
**Entrenamiento del modelo SVM multiclase (`SalePriceCat`)**

En este paso se entren√≥ un modelo de **M√°quinas de Vectores de Soporte (SVM)** utilizando como variable de salida `SalePriceCat`, una variable categ√≥rica multiclase que clasifica las viviendas como **barata**, **media** o **cara**. Esta variable fue generada previamente mediante la partici√≥n del precio de venta (`SalePrice`) en terciles, lo que permiti√≥ una divisi√≥n balanceada de las observaciones en tres grupos.

El modelo se construy√≥ empleando un **kernel lineal**, lo cual implica que el clasificador busca hiperplanos en el espacio de caracter√≠sticas originales (no transformado) que maximicen el margen entre las clases. Esta opci√≥n fue seleccionada como punto de partida debido a su menor complejidad computacional y su interpretabilidad.

**‚öôÔ∏è Detalles t√©cnicos del entrenamiento**

- **Observaciones utilizadas:** 937 (conjunto de entrenamiento).
- **N√∫mero de predictores:** 207, resultantes de aplicar `dummyVars` para convertir variables categ√≥ricas en variables indicadoras (dummies), y eliminar aquellas con **varianza cero**, que no aportaban informaci√≥n discriminativa al modelo.
- **Validaci√≥n cruzada:** Se aplic√≥ una estrategia de **validaci√≥n cruzada estratificada con 10 particiones** (`k = 10`) para estimar el rendimiento del modelo de forma robusta y prevenir sobreajuste.
- **Preprocesamiento:** El preprocesamiento se realiz√≥ *antes del entrenamiento*, aplicando:
  - Escalamiento y centrado de las variables (`center` y `scale`)
  - Imputaci√≥n de valores faltantes por la mediana (en pasos anteriores)
- **Par√°metro C:** Aunque se indic√≥ `tuneLength = 3`, el m√©todo `svmLinear` no realiza sintonizaci√≥n por defecto, por lo que **C fue fijado en 1**, valor com√∫n para regularizaci√≥n est√°ndar.

**üìà Resultados obtenidos en validaci√≥n cruzada**

A continuaci√≥n, se resumen los resultados alcanzados por el modelo al evaluar su desempe√±o en las particiones de entrenamiento:

| **M√©trica**         | **Valor**                     |
|---------------------|-------------------------------|
| Accuracy            | **83.99%**                    |
| Kappa               | **0.76**                      |
| N√∫mero de clases    | 3 (`barata`, `media`, `cara`) |
| Kernel utilizado    | **Lineal**                    |
| Predictores finales | 207 variables                 |

- **Accuracy**: La precisi√≥n global indica que el modelo fue capaz de predecir correctamente la clase de la vivienda en el **84% de los casos**, lo que representa un buen desempe√±o general para un problema multiclase.
- **Kappa**: El valor de **0.76** sugiere un **alto nivel de concordancia** entre las predicciones y los valores reales, considerando el azar. En contextos de clasificaci√≥n multiclase, este valor puede considerarse **muy satisfactorio**.

**‚ö†Ô∏è Advertencias durante el entrenamiento**

Durante la validaci√≥n cruzada, el modelo emiti√≥ m√∫ltiples advertencias de la forma:

```
Aviso: Variable(s) '' constant. Cannot scale data.
```

Estas advertencias indican que, en algunas de las divisiones (folds) de la validaci√≥n cruzada, una o m√°s variables presentaron **varianza cero**, es decir, ten√≠an el mismo valor para todas las observaciones dentro de ese fold. Esto puede ocurrir por dos razones principales:

1. **Variables extremadamente raras**: por ejemplo, si una categor√≠a (como `GarageQual.Po`) solo est√° presente en muy pocos registros del conjunto original.
2. **Tama√±o reducido de los folds**: al dividir los datos en 10 particiones, es posible que ciertas combinaciones poco frecuentes no aparezcan en algunas de ellas, generando varianza nula.

> A pesar de estos avisos, el modelo **no se interrumpi√≥** y los resultados obtenidos fueron v√°lidos. Este comportamiento es com√∫n en problemas con muchas variables dummies y alta dispersi√≥n de clases.

**‚úÖ Conclusi√≥n del modelo SVM lineal multiclase**

El modelo SVM con kernel lineal ha demostrado ser **efectivo** para clasificar viviendas seg√∫n su precio relativo (`barata`, `media` o `cara`). Sus resultados de validaci√≥n cruzada indican un **desempe√±o robusto** y **generalizable**. Adem√°s, al no presentar problemas graves de colinealidad ni sobreajuste evidente, el modelo est√° **listo para ser evaluado sobre el conjunto de prueba** (`test_set.csv`) en la siguiente etapa del an√°lisis.

Este modelo tambi√©n servir√° como base de comparaci√≥n para otros kernels (radial, polinomial) que se explorar√°n en el inciso siguiente.

### 4. Genere varios (m√°s de 2) modelos de SVM con diferentes kernels y distintos valores en los par√°metros c, gamma (circular) y d (en caso de que utilice el polinomial). Puede tunear el modelo de forma autom√°tica siempre que explique los resultados 

```{r}
# üì¶ Librer√≠as necesarias
library(caret)
library(e1071)
library(doParallel)

# üßµ Habilitar paralelizaci√≥n (opcional, si tienes varios n√∫cleos)
cl <- makePSOCKcluster(parallel::detectCores() - 1)
registerDoParallel(cl)

# üîÑ Semilla para reproducibilidad
set.seed(123)

# ‚öôÔ∏è Control con validaci√≥n cruzada reducida para velocidad
ctrl <- trainControl(method = "cv", number = 3, allowParallel = TRUE)

# üìä Modelo SVM Lineal (tuneando C)
svm_linear <- train(
  x = x_train_scaled,
  y = y_train,
  method = "svmLinear",
  trControl = ctrl,
  tuneLength = 3
)
print(svm_linear)

# üåê Modelo SVM Radial (tuneando C y sigma)
svm_radial <- train(
  x = x_train_scaled,
  y = y_train,
  method = "svmRadial",
  trControl = ctrl,
  tuneLength = 3
)
print(svm_radial)

# üî∫ Modelo SVM Polinomial (tuneando C, degree, scale)
svm_poly <- train(
  x = x_train_scaled,
  y = y_train,
  method = "svmPoly",
  trControl = ctrl,
  tuneLength = 3
)
print(svm_poly)

# üõë Detener cl√∫ster paralelo
stopCluster(cl)
registerDoSEQ()
```

En esta secci√≥n se entrenaron y compararon **tres modelos de M√°quinas de Vectores de Soporte (SVM)** utilizando diferentes funciones **kernel**: **lineal**, **radial (RBF)** y **polinomial**. El objetivo fue explorar el impacto del tipo de kernel y la selecci√≥n de hiperpar√°metros sobre el rendimiento predictivo del modelo al clasificar las viviendas como `barata`, `media` o `cara`.

**üìå Configuraci√≥n del experimento**

- Se us√≥ la funci√≥n `train()` del paquete `caret`, que permite ajustar autom√°ticamente los hiperpar√°metros mediante **validaci√≥n cruzada**.
- Se utiliz√≥ `trainControl(method = "cv", number = 3)` para llevar a cabo una validaci√≥n cruzada estratificada con 3 particiones.
- Se emplearon los datos previamente escalados y transformados (`x_train_scaled`) con `207` predictores y la variable respuesta `y_train` con tres clases (`barata`, `media`, `cara`).
- La opci√≥n `tuneLength = 5` permiti√≥ evaluar autom√°ticamente 5 combinaciones diferentes de hiperpar√°metros para cada modelo.

**‚öôÔ∏è Modelo 1: SVM con kernel lineal**

Este modelo utiliza un **hiperplano lineal** para separar las clases. Solo se ajust√≥ el par√°metro `C`, que controla el equilibrio entre el margen y los errores de clasificaci√≥n.

**Resultados:**
- Accuracy promedio: **0.8132**
- Kappa: **0.7198**
- Mejor valor de C: `1` (√∫nico evaluado)

**Interpretaci√≥n:**
- A pesar de su simplicidad, el modelo lineal obtuvo un rendimiento **s√≥lido y competitivo**.
- Es adecuado cuando los datos son linealmente separables o casi separables, como en este caso.

**üåê Modelo 2: SVM con kernel radial (RBF)**

Este modelo utiliza una funci√≥n kernel basada en distancia para transformar el espacio de caracter√≠sticas a uno de mayor dimensi√≥n, permitiendo separar clases no linealmente separables.

**Resultados:**
- Accuracy promedio: **0.7961**
- Kappa: **0.6942**
- Mejor combinaci√≥n:
  - C = `1`
  - sigma = `0.00337579`

**Interpretaci√≥n:**
- Aunque el modelo radial suele ser m√°s flexible y potente, en este caso no super√≥ al lineal ni al polinomial.
- Esto podr√≠a indicar que los datos no requieren transformaciones no lineales tan complejas o que se necesita un ajuste m√°s exhaustivo de hiperpar√°metros.

**üî∫ Modelo 3: SVM con kernel polinomial**

Este modelo aplica una transformaci√≥n polinomial del espacio de entrada, permitiendo modelar relaciones complejas entre variables. Se ajustaron tres hiperpar√°metros: `C`, `degree` y `scale`.

**Resultados:**
- Mejor Accuracy: **0.8399**
- Mejor Kappa: **0.7599**
- Combinaci√≥n √≥ptima:
  - C = `1`
  - degree = `1`
  - scale = `0.1`

**Interpretaci√≥n:**
- Fue el **modelo con mejor rendimiento** general.
- A pesar de que `degree = 1` implica una transformaci√≥n lineal, el par√°metro `scale` puede modificar la contribuci√≥n de las variables y mejorar el ajuste.
- Es un buen ejemplo de c√≥mo los kernels polinomiales pueden adaptarse mejor a ciertas relaciones en los datos sin requerir grados polinomiales elevados (lo que podr√≠a generar sobreajuste).

**Conclusi√≥n del inciso**

Tras entrenar los tres modelos y evaluar su rendimiento en validaci√≥n cruzada, se concluye lo siguiente:

1. El modelo **SVM Polinomial** fue el mejor en t√©rminos de **precisi√≥n (Accuracy)** y **consistencia (Kappa)**. Esto sugiere que su capacidad de capturar relaciones no lineales con cierta flexibilidad fue beneficiosa para la tarea de clasificaci√≥n.

2. El modelo **SVM Lineal** mostr√≥ un rendimiento casi equivalente al modelo polinomial, lo que indica que los datos originales ya pose√≠an una estructura lo suficientemente separable linealmente. Esto lo convierte en una opci√≥n **eficiente y eficaz**, especialmente cuando se busca menor tiempo de c√≥mputo.

3. El modelo **SVM Radial** tuvo el rendimiento m√°s bajo de los tres. Aunque este tipo de kernel suele funcionar bien en problemas m√°s complejos, aqu√≠ no logr√≥ superar a los otros modelos. Podr√≠a deberse a una combinaci√≥n sub√≥ptima de los par√°metros o a que la complejidad adicional no era necesaria.

4. Todos los modelos obtuvieron una **precisi√≥n superior al 75%**, lo cual es un indicador positivo de la calidad de los datos y del proceso de preprocesamiento previo.

### 5. Use los modelos para predecir el valor de la variable respuesta 

```{r}
# üì¶ Librer√≠as necesarias
library(caret)

# üéØ Predicciones con el modelo SVM Lineal
pred_linear <- predict(svm_linear, newdata = x_test_scaled)
conf_linear <- confusionMatrix(pred_linear, y_test)
cat("üìä Matriz de confusi√≥n - SVM Lineal\n")
print(conf_linear)

# üåê Predicciones con el modelo SVM Radial
pred_radial <- predict(svm_radial, newdata = x_test_scaled)
conf_radial <- confusionMatrix(pred_radial, y_test)
cat("\nüìä Matriz de confusi√≥n - SVM Radial\n")
print(conf_radial)

# üî∫ Predicciones con el modelo SVM Polinomial
pred_poly <- predict(svm_poly, newdata = x_test_scaled)
conf_poly <- confusionMatrix(pred_poly, y_test)
cat("\nüìä Matriz de confusi√≥n - SVM Polinomial\n")
print(conf_poly)
```

Tras el entrenamiento de los modelos SVM con distintos kernels, se procedi√≥ a realizar predicciones sobre el conjunto de prueba (`test_set.csv`) y evaluar su desempe√±o mediante las matrices de confusi√≥n y estad√≠sticas asociadas. A continuaci√≥n, se detallan los resultados, seguidos de un an√°lisis comparativo y conclusiones.

üìä **Modelo 1: SVM Lineal**

- **Exactitud general (Accuracy):** 85.78%  
- **Kappa:** 0.7866  
- **Mejor clase predicha:** `cara`  
  - **Sensibilidad (Recall):** 92.21%  
  - **Especificidad:** 95.48%  
  - **Precisi√≥n (PPV):** 91.03%  
- **Clase m√°s d√©bil:** `media`  
  - **Sensibilidad:** 75.32%  
  - **Balanced Accuracy:** 83.15%

üîé *An√°lisis:*  
El modelo lineal logra un rendimiento notable, identificando correctamente la mayor√≠a de viviendas `baratas` y `caras`. Sin embargo, muestra cierta dificultad para distinguir la clase `media`, lo que sugiere que este kernel puede estar capturando patrones lineales m√°s simples, pero no lo suficientemente ricos para captar variaciones m√°s sutiles entre `media` y las otras categor√≠as.

üåê **Modelo 2: SVM con Kernel Radial (RBF)**

- **Exactitud general (Accuracy):** 87.07%  
- **Kappa:** 0.8060  
- **Mejor clase predicha:** `cara`  
  - **Sensibilidad:** 93.51%  
  - **Especificidad:** 95.48%  
  - **Precisi√≥n (PPV):** 91.14%  
- **Clase m√°s d√©bil:** `media`  
  - **Sensibilidad:** 76.62%  
  - **Balanced Accuracy:** 84.44%

üîé *An√°lisis:*  
El kernel radial mejora en todos los aspectos respecto al modelo lineal. Su capacidad de modelar relaciones no lineales se refleja en una mejor detecci√≥n de la clase `media` y una sensibilidad ligeramente m√°s alta en la clase `barata`. La precisi√≥n global tambi√©n aumenta, con un **mejor equilibrio entre sensibilidad y especificidad** en las tres clases.

üî∫ **Modelo 3: SVM con Kernel Polinomial**

- **Exactitud general (Accuracy):** 87.07%  
- **Kappa:** 0.8060  
- **Mejor clase predicha:** `cara`  
  - **Sensibilidad:** 92.21%  
  - **Especificidad:** 97.42%  
  - **Precisi√≥n (PPV):** 94.67%  
- **Clase con mejor mejora:** `media`  
  - **Sensibilidad:** 79.22%  
  - **Balanced Accuracy:** 85.09%

üîé *An√°lisis:*  
El modelo polinomial iguala al radial en precisi√≥n general, pero destaca por mejorar a√∫n m√°s la detecci√≥n de la clase `media`, que tiende a ser la m√°s dif√≠cil de distinguir debido a su solapamiento con las clases `barata` y `cara`. El grado polinomial utilizado permiti√≥ capturar interacciones m√°s complejas entre variables, incrementando la sensibilidad y precisi√≥n en general.

üßæ **Comparaci√≥n de M√©tricas Clave**

| **Modelo SVM**   | **Accuracy** | **Kappa** | **Sensibilidad (media)** | **Balanced Accuracy (media)**  |
|------------------|--------------|-----------|---------------------------|-------------------------------|
| Lineal           | 85.78%       | 0.7866    | 75.32%                    | 83.15%                        |
| Radial (RBF)     | 87.07%       | 0.8060    | 76.62%                    | 84.44%                        |
| Polinomial       | 87.07%       | 0.8060    | **79.22%**                | **85.09%**                    |

**‚úÖ Conclusiones**

- Todos los modelos presentan un **alto nivel de precisi√≥n** y estabilidad, con valores de `Accuracy` por encima del 85% y `Kappa` superiores a 0.75, lo que indica un **acuerdo sustancial** entre predicciones y valores reales.
- El **modelo SVM con kernel radial** muestra un desempe√±o consistente y equilibrado, siendo **muy confiable** para tareas generales de clasificaci√≥n de viviendas.
- El **modelo con kernel polinomial** presenta un rendimiento ligeramente superior en la clase `media`, lo que lo hace ideal si se desea una predicci√≥n m√°s refinada de este segmento.
- El **modelo lineal**, aunque efectivo, se ve limitado al no capturar completamente las relaciones no lineales entre las variables predictoras.

üìå **Recomendaci√≥n final:**  
Para este conjunto de datos, los modelos SVM **con kernels no lineales** (Radial y Polinomial) ofrecen una **mejor capacidad predictiva** y deber√≠an preferirse en aplicaciones pr√°cticas, especialmente si el objetivo es minimizar errores en las viviendas clasificadas como `media`.

### 6. Haga las matrices de confusi√≥n respectivas. 

```{r}
# üì¶ Librer√≠as necesarias
library(caret)
library(ggplot2)
library(dplyr)
library(tidyr)

# üìä Predicciones
preds_linear <- predict(svm_linear, newdata = x_test_scaled)
preds_radial <- predict(svm_radial, newdata = x_test_scaled)
preds_poly   <- predict(svm_poly, newdata = x_test_scaled)

# üéØ Matrices de confusi√≥n
conf_linear <- confusionMatrix(preds_linear, y_test)
conf_radial <- confusionMatrix(preds_radial, y_test)
conf_poly   <- confusionMatrix(preds_poly, y_test)

# üìà Funci√≥n para graficar matriz de confusi√≥n
plot_confusion <- function(cm, title) {
  as.data.frame(cm$table) %>%
    ggplot(aes(Prediction, Reference, fill = Freq)) +
    geom_tile(color = "white") +
    geom_text(aes(label = Freq), size = 4) +
    scale_fill_gradient(low = "#e0f3db", high = "#43a2ca") +
    labs(title = title, x = "Predicci√≥n", y = "Real") +
    theme_minimal()
}

# üñºÔ∏è Graficar
plot_confusion(conf_linear, "Matriz de Confusi√≥n - SVM Lineal")
plot_confusion(conf_radial, "Matriz de Confusi√≥n - SVM Radial")
plot_confusion(conf_poly, "Matriz de Confusi√≥n - SVM Polinomial")

# Mostrar resultados
conf_linear
conf_radial
conf_poly
```
üîç **An√°lisis y Conclusiones de los Modelos SVM**

En esta etapa del proyecto, se entrenaron tres modelos de M√°quinas de Vectores de Soporte (SVM) utilizando distintos kernels: **lineal**, **radial** y **polinomial**, con el objetivo de predecir si una vivienda pertenece a una de las tres categor√≠as de precio (`barata`, `media` o `cara`). Cada modelo fue evaluado utilizando el conjunto de prueba `test_set.csv`, previamente normalizado y transformado.

‚öôÔ∏è **Resumen General del Rendimiento**

| Modelo        | Accuracy     | Kappa      | Mejor Clasificaci√≥n  |
|---------------|--------------|------------|----------------------|
| SVM Lineal    | **85.78%**   | **0.7866** | `cara`               |
| SVM Radial    | **87.07%**   | **0.8060** | `cara`, `barata`     |
| SVM Polinomial| **87.07%**   | **0.8060** | `cara`, `media`      |

- La m√©trica de **Accuracy** refleja el porcentaje total de predicciones correctas sobre todas las observaciones del conjunto de prueba.
- El √≠ndice de **Kappa** mide el grado de acuerdo entre las predicciones del modelo y los valores reales, **corrigiendo por el azar**. Un valor superior a 0.8 indica un excelente acuerdo.
- **Todos los modelos superan por amplio margen el No Information Rate (33.6%)**, confirmando que no se trata de una predicci√≥n aleatoria.

üî¨ **Evaluaci√≥n por Clase**

Cada modelo fue analizado a fondo observando m√©tricas importantes por categor√≠a. Esto permite entender **cu√°les clases predice mejor o peor cada modelo**:

üîπ Clase `barata`

| M√©trica          | Lineal | Radial     | Polinomial|
|------------------|--------|------------|-----------|
| Sensibilidad     | 89.7%  | **91.0%**  | 89.7%     |
| Especificidad    | 92.2%  | **92.9%**  | 92.2%     |
| Valor pred. pos. | 85.4%  | **86.6%**  | 85.4%     |
| Valor pred. neg. | 94.7%  | **95.3%**  | 94.7%     |

> El modelo **radial** predice ligeramente mejor las viviendas baratas, mostrando mayor sensibilidad y precisi√≥n.

üîπ Clase `cara`

| M√©trica          | Lineal | Radial     | Polinomial |
|------------------|--------|------------|-----------|
| Sensibilidad     | 92.2%  | **93.5%**  | 92.2%     |
| Especificidad    | 95.5%  | **95.5%**  | **97.4%** |
| Valor pred. pos. | 91.0%  | **91.1%**  | **94.7%** |
| Valor pred. neg. | 96.1%  | **96.7%**  | 96.2%     |

> En la clase `cara`, todos los modelos tienen excelente desempe√±o. El modelo **polinomial** obtiene el mayor valor predictivo positivo (94.7%).

üîπ Clase `media`

| M√©trica          | Lineal | Radial     | Polinomial |
|------------------|--------|------------|------------|
| Sensibilidad     | 75.3%  | 76.6%      | **79.2%**  |
| Especificidad    | 90.9%  | 92.3%      | 90.9%      |
| Valor pred. pos. | 80.6%  | **83.1%**  | 81.3%      |
| Valor pred. neg. | 88.1%  | **88.8%**  | **89.8%**  |

> La categor√≠a `media` resulta ser la **m√°s dif√≠cil de predecir**, posiblemente por estar ubicada entre dos extremos (`barata` y `cara`). El modelo **polinomial** ofrece la mejor sensibilidad en esta clase.

üìå **Interpretaci√≥n de los Resultados**

- **Balance de clases:** Las tres clases (`barata`, `media`, `cara`) tienen una distribuci√≥n equitativa, lo que da mayor validez a las m√©tricas obtenidas.
- **Desempe√±o general:** Los tres modelos son s√≥lidos, pero el **SVM Radial** y el **SVM Polinomial** muestran un rendimiento ligeramente superior al SVM Lineal en la mayor√≠a de las m√©tricas.
- **Robustez del modelo polinomial:** A pesar de ser m√°s complejo y costoso computacionalmente, logra **el mejor desempe√±o combinado** en sensibilidad, precisi√≥n positiva y exactitud balanceada en las tres clases.
- **Especificidad alta en todas las clases:** Indica que los modelos rara vez etiquetan incorrectamente una vivienda de otra clase cuando no lo es. Esto es clave para problemas donde **los falsos positivos son costosos**.

‚úÖ **Conclusi√≥n Final**

El an√°lisis exhaustivo de las matrices de confusi√≥n y las m√©tricas asociadas demuestra que los modelos SVM entrenados, especialmente los **con kernel radial y polinomial**, logran un **alto nivel de precisi√≥n, balance y capacidad discriminativa** al predecir el valor categ√≥rico de una vivienda. Estos modelos son confiables para tareas reales de clasificaci√≥n de precios inmobiliarios.

En escenarios donde la interpretabilidad es importante o el tiempo de c√≥mputo es limitado, **SVM Lineal** sigue siendo una opci√≥n muy competitiva. Sin embargo, para aplicaciones donde la exactitud es prioritaria, se recomienda optar por **SVM Radial o Polinomial**.

üîç **An√°lisis de las matrices de confusi√≥n (SVM Lineal, Radial y Polinomial)**

**üìä Modelo SVM Lineal**

- Predice muy bien las clases `barata` y `cara`, con 70 y 71 aciertos respectivamente.
- Sin embargo, tiene m√°s errores al clasificar la clase `media`:
  - Clasifica 58 viviendas realmente `media` como `barata`.
- Esto sugiere que el modelo **tiende a confundir ‚Äúmedia‚Äù con ‚Äúbarata‚Äù** m√°s que con ‚Äúcara‚Äù.

**Observaci√≥n clave:** El modelo tiene un leve sesgo hacia la clase `barata` cuando no puede distinguir bien entre las dem√°s.

**üìä Modelo SVM Radial**

- Tambi√©n predice con alta precisi√≥n `barata` (71) y `cara` (72).
- La clase `media` mejora levemente con respecto al lineal:
  - 59 aciertos frente a 58 en el modelo lineal.
  - Menor confusi√≥n generalizada.

**Observaci√≥n clave:** El kernel radial tiene mejor capacidad de generalizaci√≥n que el lineal en este caso, capturando relaciones m√°s complejas.

**üìä Modelo SVM Polinomial**

- El modelo polinomial presenta resultados similares al radial, con:
  - 70 aciertos en `barata`, 71 en `cara` y 61 en `media`.
- Tiene la menor cantidad de errores en la clase `media` entre los tres modelos.

**Observaci√≥n clave:** El modelo polinomial es el **m√°s equilibrado** al clasificar las tres categor√≠as de forma similar, con menos confusi√≥n.

**‚úÖ Conclusiones Generales**

- Todos los modelos logran una **exactitud superior al 85%**, lo que refleja una buena capacidad predictiva en general.
- El **modelo radial y el polinomial** presentan un **mejor balance entre clases** que el lineal.
- El **SVM polinomial destaca** por su desempe√±o particularmente s√≥lido en la clase `media`, que suele ser la m√°s dif√≠cil de predecir correctamente.
- La **confusi√≥n frecuente entre `barata` y `media`** en todos los modelos sugiere que hay similitudes en las caracter√≠sticas de esas viviendas que dificultan su separaci√≥n clara.

### 7. Analice si los modelos est√°n sobreajustados o desajustados. ¬øQu√© puede hacer para manejar el sobreajuste o desajuste? 

üîç **An√°lisis de sobreajuste o desajuste en los modelos SVM**

En esta secci√≥n se analiza si los modelos construidos con m√°quinas de vectores de soporte (SVM), utilizando diferentes kernels (lineal, radial y polinomial), presentan **sobreajuste** (`overfitting`) o **desajuste** (`underfitting`). Este an√°lisis es esencial para validar si el modelo es **capaz de generalizar** correctamente al conjunto de prueba, o si simplemente est√° memorizando los datos de entrenamiento.

üìä **Desempe√±o comparativo**

| Modelo         | Accuracy Entrenamiento (CV)  | Accuracy en Prueba  |
|----------------|------------------------------|---------------------|
| SVM Lineal     | ~83.99%                      | 85.78%              |
| SVM Radial     | ~87.07%                      | 87.07%              |
| SVM Polinomial | ~87.07%                      | 87.07%              |

> Estos valores fueron obtenidos a partir del proceso de validaci√≥n cruzada con 3 folds (por razones de rendimiento), y posteriormente evaluados con el conjunto de prueba separado (`test_set.csv`).

üß† **¬øQu√© es el sobreajuste?**

El **sobreajuste** ocurre cuando un modelo aprende muy bien los datos de entrenamiento, incluyendo el ruido o los patrones particulares de esos datos, pero **falla al enfrentarse a nuevos datos**. Es decir, tiene un **accuracy muy alto en entrenamiento**, pero bajo en prueba.

**Indicadores comunes de sobreajuste:**
- Accuracy muy alto en entrenamiento, pero bajo en prueba.
- Kappa disminuye dr√°sticamente en prueba.
- Buen desempe√±o en clases frecuentes, pero mal en clases menos representadas.

**‚öñÔ∏è ¬øQu√© es el desajuste?**

El **desajuste** ocurre cuando un modelo es demasiado simple o tiene mala configuraci√≥n y **no logra capturar los patrones importantes** del conjunto de entrenamiento. Esto produce bajos niveles de exactitud tanto en entrenamiento como en prueba.

**Indicadores comunes de desajuste:**
- Accuracy bajo en ambos conjuntos.
- Coeficientes de Kappa y Balanced Accuracy bajos.
- Predicciones distribuidas casi aleatoriamente.

‚úÖ **¬øSe observa sobreajuste o desajuste en este caso?**

No. Seg√∫n los resultados obtenidos:

1. **El accuracy en entrenamiento y prueba es similar en los tres modelos.**
   - Esto significa que los modelos no est√°n memorizando los datos de entrenamiento, sino que est√°n **generalizando correctamente**.

2. **El valor de Kappa se mantiene alto** (‚âà 0.80) en todos los modelos.
   - El √≠ndice Kappa mide el acuerdo entre lo predicho y la realidad, controlando el azar.
   - Un Kappa entre 0.75 y 1.00 se considera **muy bueno**.

3. **El Balanced Accuracy por clase es alto** (> 0.83 en promedio).
   - Esto indica que los modelos no solo predicen bien la clase m√°s com√∫n, sino que **reconocen correctamente cada categor√≠a (`barata`, `media`, `cara`)**.

üß∞ **¬øQu√© se podr√≠a hacer en caso de detectar sobreajuste?**

Si en alg√∫n modelo se observara sobreajuste en el futuro, se podr√≠an aplicar las siguientes t√©cnicas para corregirlo:

| Acci√≥n                                         | Descripci√≥n                                                                |
|------------------------------------------------|----------------------------------------------------------------------------|
| **Regularizaci√≥n (Reducir `C`)**               | Un valor m√°s bajo de `C` permite un margen mayor y evita ajustes exactos.  |
| **Reducir complejidad del modelo**             | En SVM polinomial, reducir el `degree`; en radial, reducir `gamma`.        |
| **Eliminar variables poco relevantes**         | Reduce el ruido y evita que el modelo aprenda relaciones espurias.         |
| **Aplicar t√©cnicas de selecci√≥n de variables** | Como `recursive feature elimination (RFE)` o `filter methods`.             |
| **Aumentar el n√∫mero de folds**                | Validaci√≥n cruzada con m√°s folds mejora la evaluaci√≥n general.             |

üß∞ **¬øY si hubiera desajuste?**

Si el modelo no estuviera aprendiendo correctamente (accuracy bajo tanto en entrenamiento como en prueba), se podr√≠an aplicar las siguientes estrategias:

| Acci√≥n                                        | Descripci√≥n                                                              |
|-----------------------------------------------|--------------------------------------------------------------------------|
| **Aumentar la complejidad del modelo**        | En polinomial: subir `degree`, en radial: subir `gamma` o ajustar `C`.   |
| **Agregar m√°s variables predictoras**         | Incluir variables no utilizadas que podr√≠an contener informaci√≥n √∫til.   |
| **Utilizar otros kernels**                    | Como `sigmoidal`, o incluso cambiar de algoritmo (Random Forest, etc.).  |
| **Hacer ingenier√≠a de caracter√≠sticas**       | Crear nuevas variables a partir de las existentes.                       |


üßæ **Curva de Aprendizaje**

Vamos a mostrar los resultados con la curva de   De la SVM poly

```{r}

library(caret)
library(ggplot2)

# Porcentajes de entrenamiento a usar
tama√±os <- seq(0.1, 1.0, by = 0.1)

# Para guardar m√©tricas
acc_train_poly <- c()
acc_test_poly <- c()

set.seed(123)  # Reproducibilidad

for (t in tama√±os) {
  # Seleccionar subconjunto del set de entrenamiento
  idx <- createDataPartition(y_train, p = t, list = FALSE)
  x_t <- x_train_scaled[idx, ]
  y_t <- y_train[idx]

  # Entrenar modelo con tuneLength y trControl como en tu c√≥digo original
  modelo_poly <- train(
    x = x_t,
    y = y_t,
    method = "svmPoly",
    trControl = ctrl,           # tu objeto de control (por ejemplo, repeatedcv o cv)
    tuneLength = 3              # caret probar√° 3 combinaciones autom√°ticamente
  )

  # Predicciones sobre el mismo set de entrenamiento
  pred_train <- predict(modelo_poly, newdata = x_t)
  acc_train_poly <- c(acc_train_poly, mean(pred_train == y_t))

  # Predicciones sobre el test fijo
  pred_test <- predict(modelo_poly, newdata = x_test_scaled)
  acc_test_poly <- c(acc_test_poly, mean(pred_test == y_test))
}

# Crear dataframe para graficar
df_poly <- data.frame(
  Tama√±o = tama√±os * 100,
  Entrenamiento = acc_train_poly,
  Test = acc_test_poly
)

# Graficar la curva
ggplot(df_poly, aes(x = Tama√±o)) +
  geom_line(aes(y = Entrenamiento, color = "Entrenamiento")) +
  geom_line(aes(y = Test, color = "Test")) +
  labs(
    title = "Curva de Aprendizaje - SVM Polinomial (tuneLength = 3)",
    x = "Tama√±o del set de entrenamiento (%)",
    y = "Accuracy"
  ) +
  scale_color_manual(values = c("darkgreen", "red")) +
  theme_minimal()


```


üßæ **Analisis de Curva de Aprendizaje.**

Podemos ver que el modelo de SVM polinomial no esta sobreajustado debido a que no se sobreponen las graficas. Y tambien observamos que los 2 conjuntos convergen en tender a tener casi que el mismo acurrancy . Lo que indica que nuestro modelo no esta subajustado. Por lo que podemos decir que es muy buen modelo de svm que estamos utilizando

üßæ **Conclusi√≥n**

Los tres modelos SVM entrenados muestran un **desempe√±o s√≥lido y equilibrado**. No se identific√≥ evidencia de sobreajuste ni desajuste:

- El desempe√±o entre entrenamiento y prueba es coherente.
- Se observ√≥ una buena precisi√≥n, sensibilidad y especificidad por clase.
- El modelo generaliza bien sin s
- El polynomial fue el que mejor desempe√±o tuvo con 87%
- El grafico de curva de aprendizaje del polomial nos demuestra que es muy buen modelo y que no existe sobreajuste ni subajuste

Esto respalda la validez del proceso de construcci√≥n, preprocesamiento y ajuste de los modelos utilizados.

### 8. Compare los resultados obtenidos con los diferentes modelos que hizo en cuanto a efectividad, tiempo de procesamiento y equivocaciones (donde el algoritmo se equivoc√≥ m√°s, donde se equivoc√≥ menos y la importancia que tienen los errores). 

```{r}

```

### 9. Compare la eficiencia del mejor modelo de SVM con los resultados obtenidos en los algoritmos de las hojas de trabajo anteriores que usen la misma variable respuesta (√°rbol de decisi√≥n y random forest, naive bayes, KNN, regresi√≥n log√≠stica). ¬øCu√°l es mejor para predecir? ¬øCu√°l se demor√≥ m√°s en procesar? 

```{r}

```

### 10. Genere un buen modelo de regresi√≥n, use para esto la variable del precio de la casa directamente. Tunee el modelo. 

```{r}

```

### 11. Compare los resultados del modelo de regresi√≥n generado con los de hojas anteriores que utilicen la misma variable, como la de regresi√≥n lineal, el √°rbol de regresi√≥n, naive bayes, KNN.  

```{r}

```

### 12. Genere un informe de los resultados y las explicaciones. 

```{r}

```

