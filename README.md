# ğŸ“Š Entrega 6: MÃ¡quinas de Vectores de Soporte (SVM)

---

# ğŸ§  Proyecto de ClasificaciÃ³n Multiclase: PredicciÃ³n de CategorÃ­as de Precio de Viviendas

---

## ğŸ« Universidad del Valle de Guatemala - Campus Central  
**Facultad:** IngenierÃ­a  
**Departamento:** Ciencias de la ComputaciÃ³n  
**Curso:** MinerÃ­a de Datos (CC3074) - SecciÃ³n 10  
**Semestre:** I â€“ 2025  
**Proyecto:** Proyecto #2  
**Entrega:** Entrega 6 â€“ MÃ¡quinas de Vectores de Soporte (SVM)  

---

## ğŸ‘¥ Integrantes del Grupo #1  
- **Pablo Daniel Barillas Moreno** - *CarnÃ© No. 22193*  
- **Mathew Cordero Aquino** - *CarnÃ© No. 22982*  

---

## ğŸ“Œ DescripciÃ³n del Proyecto  

En esta entrega se utilizÃ³ el algoritmo de **MÃ¡quinas de Vectores de Soporte (SVM)** para predecir si una vivienda es **barata**, **media** o **cara**, utilizando el conjunto de datos de Kaggle **â€œHouse Prices: Advanced Regression Techniquesâ€**.  
El modelo se entrenÃ³ sobre los conjuntos `train_set.csv` y `test_set.csv`, previamente definidos en entregas anteriores.

---

## ğŸ” Actividades Realizadas  

### 1ï¸âƒ£ Serie 1: ReutilizaciÃ³n de conjuntos  
- Se cargaron `train_set.csv` (937 observaciones) y `test_set.csv` (232 observaciones).
- Se validÃ³ que `SalePriceCat` mantuviera la distribuciÃ³n balanceada: 313 baratas, 312 medias, 312 caras.

### 2ï¸âƒ£ Serie 2: Preprocesamiento para SVM  
- Se eliminaron columnas irrelevantes (`Id`, `SalePrice`).
- Las variables categÃ³ricas fueron transformadas en **dummies** con `dummyVars()`.
- Se centraron y escalaron los datos con `preProcess()`.
- Se eliminaron predictores con varianza cero y se alinearon columnas entre train y test.

### 3ï¸âƒ£ Serie 3: Entrenamiento del modelo SVM multiclase  
- Se entrenÃ³ un modelo **SVM lineal** con `SalePriceCat` como respuesta.
- Se usaron 207 predictores y validaciÃ³n cruzada de 10 folds.
- Resultados del modelo lineal:
  - **Accuracy:** 85.78%
  - **Kappa:** 0.7866
- El modelo mostrÃ³ buen rendimiento, sin errores crÃ­ticos.

### 4ï¸âƒ£ Serie 4: ComparaciÃ³n con otros kernels  
- Se entrenaron 3 modelos de SVM:
  - **SVM lineal:** Accuracy 85.8%
  - **SVM radial:** Accuracy 87.0%
  - **SVM polinomial:** Accuracy 87.0%
- Se exploraron diferentes valores de **C**, **sigma** y **degree**.
- Se utilizÃ³ validaciÃ³n cruzada de 3 folds para reducir tiempo de cÃ³mputo.

### 5ï¸âƒ£ Serie 5: EvaluaciÃ³n sobre conjunto de prueba  
- Se realizaron predicciones sobre `test_set.csv`.
- Se generaron y analizaron matrices de confusiÃ³n para cada modelo.
- Las mejores mÃ©tricas fueron:
  - **Balanced Accuracy (SVM radial):** 91.95% (barata), 94.50% (cara), 84.44% (media)
  - **Kappa (SVM radial/polinomial):** 0.806

### 6ï¸âƒ£ Serie 6: VisualizaciÃ³n de Resultados  
- Se generaron **grÃ¡ficos de matriz de confusiÃ³n** con `ggplot2`.
- Se compararon visualmente las predicciones correctas y los errores por clase.

### 7ï¸âƒ£ Serie 7: AnÃ¡lisis de Overfitting  
- Al comparar el desempeÃ±o entre entrenamiento y prueba no se observaron diferencias sustanciales.
- Se concluyÃ³ que los modelos estÃ¡n **bien ajustados** y no presentan overfitting.
- Se sugirieron mejoras como regularizaciÃ³n o reducciÃ³n de predictores para futuros escenarios.

---

## ğŸ“¦ Limpieza y TransformaciÃ³n de Datos  

- ConversiÃ³n de variables categÃ³ricas a factores.
- DummificaciÃ³n con `caret::dummyVars()`.
- EliminaciÃ³n de variables con varianza cero.
- AlineaciÃ³n de columnas entre `train` y `test`.
- EstandarizaciÃ³n de datos (centrado y escalado).

---

## ğŸ›  Herramientas Utilizadas  

- **Lenguaje:** R  
- **Entorno:** RStudio  
- **LibrerÃ­as:** `caret`, `dplyr`, `ggplot2`, `e1071`, `doParallel`  
- **Datos:** Kaggle House Prices (`train.csv`)  
- **Control de versiones:** GitHub  

---

## ğŸ“¢ Hallazgos Destacados  

âœ”ï¸ Los tres modelos de SVM alcanzaron **precisiones superiores al 85%**.  
âœ”ï¸ El **SVM radial y polinomial** obtuvieron mejor desempeÃ±o general que el lineal.  
âœ”ï¸ La clase mÃ¡s difÃ­cil de predecir fue **media**, con menor sensibilidad.  
âœ”ï¸ No se detectÃ³ **sobreajuste**, gracias a la validaciÃ³n cruzada y preprocesamiento riguroso.  
âœ”ï¸ Las matrices de confusiÃ³n y sus visualizaciones permitieron entender los errores comunes.  
âœ”ï¸ El pipeline de SVM queda listo para ser comparado con modelos como Random Forest o XGBoost.
