# üìä Entrega 6: M√°quinas de Vectores de Soporte (SVM)

---

# üß† Proyecto de Clasificaci√≥n Multiclase: Predicci√≥n de Categor√≠as de Precio de Viviendas

---

## üè´ Universidad del Valle de Guatemala - Campus Central  
**Facultad:** Ingenier√≠a  
**Departamento:** Ciencias de la Computaci√≥n  
**Curso:** Miner√≠a de Datos (CC3074) - Secci√≥n 10  
**Semestre:** I ‚Äì 2025  
**Proyecto:** Proyecto #2  
**Entrega:** Entrega 6 ‚Äì M√°quinas de Vectores de Soporte (SVM)  

---

## üë• Integrantes del Grupo #1  
- **Pablo Daniel Barillas Moreno** - *Carn√© No. 22193*  
- **Mathew Cordero Aquino** - *Carn√© No. 22982*  

---

## üìå Descripci√≥n del Proyecto  

En esta entrega se utiliz√≥ el algoritmo de **M√°quinas de Vectores de Soporte (SVM)** para predecir si una vivienda es **barata**, **media** o **cara**, utilizando el conjunto de datos de Kaggle **‚ÄúHouse Prices: Advanced Regression Techniques‚Äù**.  
El modelo se entren√≥ sobre los conjuntos `train_set.csv` y `test_set.csv`, previamente definidos en entregas anteriores.

---

## üîé Actividades Realizadas  

### Serie 1: Reutilizaci√≥n de conjuntos  
- Se cargaron `train_set.csv` (937 observaciones) y `test_set.csv` (232 observaciones).
- Se valid√≥ que `SalePriceCat` mantuviera la distribuci√≥n balanceada: 313 baratas, 312 medias, 312 caras.

### Serie 2: Preprocesamiento para SVM  
- Se eliminaron columnas irrelevantes (`Id`, `SalePrice`).
- Las variables categ√≥ricas fueron transformadas en **dummies** con `dummyVars()`.
- Se centraron y escalaron los datos con `preProcess()`.
- Se eliminaron predictores con varianza cero y se alinearon columnas entre train y test.

### Serie 3: Entrenamiento del modelo SVM multiclase  
- Se entren√≥ un modelo **SVM lineal** con `SalePriceCat` como respuesta.
- Se usaron 207 predictores y validaci√≥n cruzada de 10 folds.
- Resultados del modelo lineal:
  - **Accuracy:** 85.78%
  - **Kappa:** 0.7866
- El modelo mostr√≥ buen rendimiento, sin errores cr√≠ticos.

### Serie 4: Comparaci√≥n con otros kernels  
- Se entrenaron 3 modelos de SVM:
  - **SVM lineal:** Accuracy 85.8%
  - **SVM radial:** Accuracy 87.0%
  - **SVM polinomial:** Accuracy 87.0%
- Se exploraron diferentes valores de **C**, **sigma** y **degree**.
- Se utiliz√≥ validaci√≥n cruzada de 3 folds para reducir tiempo de c√≥mputo.

### Serie 5: Evaluaci√≥n sobre conjunto de prueba  
- Se realizaron predicciones sobre `test_set.csv`.
- Se generaron y analizaron matrices de confusi√≥n para cada modelo.
- Las mejores m√©tricas fueron:
  - **Balanced Accuracy (SVM radial):** 91.95% (barata), 94.50% (cara), 84.44% (media)
  - **Kappa (SVM radial/polinomial):** 0.806

### Serie 6: Visualizaci√≥n de Resultados  
- Se generaron **gr√°ficos de matriz de confusi√≥n** con `ggplot2`.
- Se compararon visualmente las predicciones correctas y los errores por clase.

### Serie 7: An√°lisis de Overfitting  
- Al comparar el desempe√±o entre entrenamiento y prueba no se observaron diferencias sustanciales.
- Se concluy√≥ que los modelos est√°n **bien ajustados** y no presentan overfitting.
- Se sugirieron mejoras como regularizaci√≥n o reducci√≥n de predictores para futuros escenarios.

### Serie 8: Evaluaci√≥n en Conjunto de Prueba  
- Se utilizaron los tres modelos entrenados (SVM Lineal, Radial y Polinomial) para predecir la categor√≠a `SalePriceCat` en el conjunto de prueba.
- Se generaron las **matrices de confusi√≥n** para cada modelo.
- Se calcularon m√©tricas como **Accuracy**, **Kappa**, **Sensibilidad**, **Especificidad**, **Valor Predictivo Positivo** y **Balanced Accuracy**.

**Resultados destacados:**
- **SVM Lineal:** Accuracy = 85.78%, Kappa = 0.7866
- **SVM Radial:** Accuracy = 87.07%, Kappa = 0.806
- **SVM Polinomial:** Accuracy = 87.07%, Kappa = 0.806

> El modelo SVM Radial y el Polinomial presentaron mejor rendimiento que el Lineal.

### Serie 9: An√°lisis Visual de Resultados  
- Se graficaron las matrices de confusi√≥n para los tres modelos.
- Los gr√°ficos permitieron visualizar los aciertos y errores de cada modelo por clase.
- Se observ√≥ que el modelo SVM Radial tiene **mejor sensibilidad** generalizada y menos errores de clasificaci√≥n cruzada.

### Serie 10: An√°lisis de Overfitting / Underfitting  
- Comparando los resultados de entrenamiento y prueba, se concluy√≥ que **no hubo sobreajuste** (overfitting).
- Tanto el rendimiento en validaci√≥n cruzada como en el conjunto de prueba fue consistente, indicando **buen balance** entre sesgo y varianza.

**¬øQu√© hacer en caso de detectar overfitting?**
- Usar **regularizaci√≥n** ajustando el par√°metro `C`.
- Implementar t√©cnicas de **reducci√≥n de dimensionalidad** como PCA.
- Aumentar el tama√±o de los datos o realizar m√°s limpieza de outliers.

**¬øQu√© hacer en caso de underfitting?**
- Probar kernels m√°s flexibles (por ejemplo, polinomial de mayor grado o radial con diferente `gamma`).
- Ajustar hiperpar√°metros `C`, `degree`, `gamma`.

### Serie 11: Comparaci√≥n entre Modelos  
- **SVM Lineal** tuvo buena precisi√≥n general, pero fue superado por los otros kernels.
- **SVM Radial** mostr√≥ un rendimiento ligeramente superior en todas las m√©tricas.
- **SVM Polinomial** obtuvo un desempe√±o muy similar al Radial, siendo competitivo especialmente en la categor√≠a ‚Äúcara‚Äù.

**Conclusi√≥n:** El mejor modelo fue **SVM Radial**, seguido muy de cerca por **SVM Polinomial**.

### Serie 12: Preparaci√≥n Final de Resultados  
- Se almacenaron las predicciones finales de los tres modelos.
- Se organizaron los resultados en tablas y gr√°ficos para facilitar su interpretaci√≥n.
- Se dejaron listos los scripts para futuras comparaciones o an√°lisis adicionales.

---

## üì¶ Limpieza y Transformaci√≥n de Datos  

- Conversi√≥n de variables categ√≥ricas a factores.
- Dummificaci√≥n con `caret::dummyVars()`.
- Eliminaci√≥n de variables con varianza cero.
- Alineaci√≥n de columnas entre `train` y `test`.
- Estandarizaci√≥n de datos (centrado y escalado).

---

## üõ† Herramientas Utilizadas  

- **Lenguaje:** R  
- **Entorno:** RStudio  
- **Librer√≠as:** `caret`, `dplyr`, `ggplot2`, `e1071`, `doParallel`  
- **Datos:** Kaggle House Prices (`train.csv`)  
- **Control de versiones:** GitHub  

---

## üì¢ Hallazgos Destacados  

‚úîÔ∏è Los tres modelos de SVM alcanzaron **precisiones superiores al 85%**.  
‚úîÔ∏è El **SVM radial y polinomial** obtuvieron mejor desempe√±o general que el lineal.  
‚úîÔ∏è La clase m√°s dif√≠cil de predecir fue **media**, con menor sensibilidad.  
‚úîÔ∏è No se detect√≥ **sobreajuste**, gracias a la validaci√≥n cruzada y preprocesamiento riguroso.  
‚úîÔ∏è Las matrices de confusi√≥n y sus visualizaciones permitieron entender los errores comunes.  
‚úîÔ∏è El pipeline de SVM queda listo para ser comparado con modelos como Random Forest o XGBoost.
